{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a7280c45",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from gym import Env\n",
    "from gym.spaces import Box, Discrete\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "00059f96",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomEnv(Env):\n",
    "    def __init__(self):\n",
    "        self.action_space = Discrete(3)\n",
    "        self.observation_space = Box(low=np.array([0]), high=np.array([100]))\n",
    "        self.state = 32 + random.randint(-3,3)\n",
    "        self.shower_length = 60\n",
    "        \n",
    "    def step(self, action):\n",
    "        self.state += action -1 \n",
    "        self.shower_length -= 1 \n",
    "        \n",
    "        if self.state >=37 and self.state <=40: \n",
    "            reward =1 \n",
    "        else: \n",
    "            reward = -1 \n",
    "        \n",
    "        if self.shower_length <= 0: \n",
    "            done = True\n",
    "        else:\n",
    "            done = False\n",
    "        \n",
    "        info = {}\n",
    "        \n",
    "        # Return step information\n",
    "        return self.state, reward, done, info\n",
    "    \n",
    "    def reset(self):\n",
    "        self.state = 32 + random.randint(-3,3)\n",
    "        self.shower_length = 60 \n",
    "        return self.state\n",
    "    \n",
    "    def render(self, mode = \"human\"):\n",
    "        print(self.state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "3a54c8f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = CustomEnv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "cf1b528d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([70.73981], dtype=float32)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.observation_space.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "5a52200a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.action_space.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "a215f399",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:1 Score:26\n",
      "Episode:2 Score:20\n",
      "Episode:3 Score:-28\n",
      "Episode:4 Score:-42\n",
      "Episode:5 Score:-4\n",
      "Episode:6 Score:-48\n",
      "Episode:7 Score:34\n",
      "Episode:8 Score:-52\n",
      "Episode:9 Score:6\n",
      "Episode:10 Score:6\n",
      "Episode:11 Score:28\n",
      "Episode:12 Score:0\n",
      "Episode:13 Score:-28\n",
      "Episode:14 Score:8\n",
      "Episode:15 Score:-60\n",
      "Episode:16 Score:-14\n",
      "Episode:17 Score:-2\n",
      "Episode:18 Score:-60\n",
      "Episode:19 Score:-18\n",
      "Episode:20 Score:10\n"
     ]
    }
   ],
   "source": [
    "episodes = 20 #20 shower episodes\n",
    "for episode in range(1, episodes+1):\n",
    "    state = env.reset()\n",
    "    done = False\n",
    "    score = 0 \n",
    "    \n",
    "    while not done:\n",
    "        action = env.action_space.sample()\n",
    "        n_state, reward, done, info = env.step(action)\n",
    "        score+=reward\n",
    "        #env.render()\n",
    "    print('Episode:{} Score:{}'.format(episode, score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7f7f8b38",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "899ded6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "states = env.observation_space.shape\n",
    "actions = env.action_space.n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "9dbfee73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "c66a047e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1,)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8c87fe9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(states, actions):\n",
    "    model = Sequential()    \n",
    "    model.add(Dense(24, activation='relu', input_shape=states))\n",
    "    model.add(Dense(24, activation='relu'))\n",
    "    model.add(Dense(actions, activation='linear'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "a5a2a500",
   "metadata": {},
   "outputs": [],
   "source": [
    "del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "6b87494f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_model(states, actions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "a3b91fae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_9 (Dense)             (None, 24)                48        \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 24)                600       \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 3)                 75        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 723\n",
      "Trainable params: 723\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "b0e87d98",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rl.agents import DQNAgent\n",
    "from rl.policy import BoltzmannQPolicy\n",
    "from rl.memory import SequentialMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "02b47a80",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_agent(model, actions):\n",
    "    policy = BoltzmannQPolicy()\n",
    "    memory = SequentialMemory(limit=50000, window_length=1)\n",
    "    dqn = DQNAgent(model=model, memory=memory, policy=policy, \n",
    "                  nb_actions=actions, nb_steps_warmup=10, target_model_update=1e-2)\n",
    "    return dqn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "3c168d2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-13 16:49:16.293691: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-12-13 16:49:16.358484: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-12-13 16:49:16.450434: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training for 2000 steps ...\n",
      "Interval 1 (0 steps performed)\n",
      "\r",
      "    1/10000 [..............................] - ETA: 31:01 - reward: -1.0000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-13 16:49:16.601770: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-12-13 16:49:16.680912: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-12-13 16:49:16.698455: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-12-13 16:49:16.811203: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-12-13 16:49:16.976217: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-12-13 16:49:17.058137: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-12-13 16:49:17.080548: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-12-13 16:49:17.322460: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-12-13 16:49:17.403466: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-12-13 16:49:17.487890: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   22/10000 [..............................] - ETA: 8:13 - reward: -1.0000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-13 16:49:17.565844: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 1998/10000 [====>.........................] - ETA: 2:10 - reward: -1.0000done, took 32.884 seconds\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2db2ddc60>"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dqn = build_agent(model, actions)\n",
    "dqn.compile(Adam(learning_rate=1e-3), metrics=['mae'])\n",
    "dqn.fit(env, nb_steps=2000, visualize=False, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "41151767",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing for 1 episodes ...\n",
      "30\n",
      "29\n",
      "28\n",
      "27\n",
      "26\n",
      "25\n",
      "24\n",
      "23\n",
      "22\n",
      "21\n",
      "20\n",
      "19\n",
      "18\n",
      "17\n",
      "16\n",
      "15\n",
      "14\n",
      "13\n",
      "12\n",
      "11\n",
      "10\n",
      "9\n",
      "8\n",
      "7\n",
      "6\n",
      "5\n",
      "4\n",
      "3\n",
      "2\n",
      "1\n",
      "0\n",
      "-1\n",
      "-2\n",
      "-3\n",
      "-4\n",
      "-5\n",
      "-6\n",
      "-7\n",
      "-8\n",
      "-9\n",
      "-10\n",
      "-11\n",
      "-12\n",
      "-13\n",
      "-14\n",
      "-15\n",
      "-16\n",
      "-17\n",
      "-18\n",
      "-19\n",
      "-20\n",
      "-21\n",
      "-22\n",
      "-23\n",
      "-24\n",
      "-25\n",
      "-26\n",
      "-27\n",
      "-28\n",
      "-29\n",
      "Episode 1: reward: -60.000, steps: 60\n",
      "-60.0\n"
     ]
    }
   ],
   "source": [
    "results = dqn.test(env, nb_episodes=1, visualize=True)\n",
    "print(np.mean(results.history['episode_reward']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c49befd8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
